**This is the initial screen users see after launching the app. The interface is cleanly divided into two sections:
Left: A text input for entering the research topic and a "Run Research" button.
Right: A placeholder panel titled "Knowledge Graph" with a message prompting the user to run research first.**
<img width="1496" height="829" alt="Screenshot 2025-08-04 at 1 33 47 PM" src="https://github.com/user-attachments/assets/d678edde-c8b9-401e-b188-a6611fc6b0e8" />

**After entering a query, the system shows a loading spinner (Searching...) and begins executing the research pipeline.
The left column displays a live “Steps completed” list (e.g., Plan Node, Gather Info Node), showing progress as LangGraph nodes execute.
The right graph panel remains hidden until research is completed.**
<img width="1496" height="829" alt="Screenshot 2025-08-04 at 1 33 47 PM" src="https://github.com/user-attachments/assets/cc928f57-09bb-4274-9b69-801b320654a1" />

**The research pipeline has finished executing all nodes.
A green success message (“Research completed!”) is shown.
The final interactive knowledge graph is now fully rendered.
Users can view the full model thinking and structured summary report below.**
<img width="1500" height="801" alt="Screenshot 2025-08-04 at 1 36 31 PM" src="https://github.com/user-attachments/assets/2cd84482-d3ef-4eb8-bf22-abb5f86ac396" />

**The "Model Thinking" section is now expanded, showing the internal reasoning trace generated by the LLM.
On the right, an early preview of the knowledge graph begins to render, displaying central nodes and relationships.
Each node represents a concept, model, application, etc., inferred from the research.**
<img width="1504" height="848" alt="Screenshot 2025-08-04 at 1 35 03 PM" src="https://github.com/user-attachments/assets/59e5cdab-7fef-46cb-93e0-078e24e8f090" />

**The research pipeline has finished executing all nodes.
A green success message (“Research completed!”) is shown.
The final interactive knowledge graph is now fully rendered.
Users can view the full model thinking and structured summary report below.**
<img width="782" height="724" alt="Screenshot 2025-08-04 at 1 36 45 PM" src="https://github.com/user-attachments/assets/4b5f66bc-babf-4eff-9104-f670f5224bb2" />

**This image shows a node selected in the graph, revealing a rich side panel.
Details include the node’s ID, type (e.g., APPLICATION), name, and full description.
This allows users to inspect semantic relationships and entity descriptions visually and interactively.**
<img width="783" height="701" alt="Screenshot 2025-08-04 at 1 36 57 PM" src="https://github.com/user-attachments/assets/912c0d5f-141e-4f15-b93a-8e916a7cc3a0" />

**The layout dropdown menu is expanded, allowing users to switch between graph layouts:
Options include: dagre, grid, circle, concentric, random, breadthfirst, etc.
Useful for visual clarity when graphs become dense or highly connected.**
<img width="1487" height="807" alt="Screenshot 2025-08-04 at 1 37 15 PM" src="https://github.com/user-attachments/assets/985cb902-8acf-44f5-8687-1b3f4ea87804" />

**At the bottom of the output, the citations are shown with optional confidence scores.
Each source is rendered in APA-like style with clickable links (e.g., arXiv, external PDFs).
This section highlights the traceability and credibility of the generated research.**
<img width="1497" height="871" alt="Screenshot 2025-08-04 at 1 37 29 PM" src="https://github.com/user-attachments/assets/e6d5dd93-951d-475f-addc-8a9a31f8013a" />






# 🧠 Research Agent

Research Agent is a modular, automated research assistant built with LangGraph, LangChain, and LLMs. Given a single research query, it executes a complete multi-step pipeline:

- Plans the Research Scope: Breaks down the main query into relevant subtopics using an LLM-powered planner.
- Gathers Documents: Searches academic and web sources to retrieve high-quality, relevant documents.
- Processes and Filters Content: Parses retrieved content, extracts key text from summaries or full PDFs, and filters noise.
- Synthesizes a Report: Generates a structured, human-readable research report across all subtopics using LLM synthesis.
- Handles Citations Automatically: Formats both raw citation metadata and readable references for inclusion in the report or UI.
- Modular & Extensible: Each step (planning, search, processing, synthesis, citation) is a standalone LangGraph node — easily extendable or swappable.
- A Streamlit-based research tool that uses LangGraph to generate structured reports and visualize entity relationships in an interactive knowledge graph.


---

## 🚀 Features

- 🌐 Web & Academic Search: Integrates Google Search and arXiv API to gather relevant research data
- 📄 Document Parsing: Extracts content from PDFs and text files for deeper analysis
- 🧠 LLM-Based Synthesis: Uses LLaMA 3 via the Groq API for high-speed, accurate reasoning
- 📝 Structured Report Generation: Formats research findings into clean, readable markdown
- 🔗 Citation Generation: Outputs APA-style references for sourced content
- 🖥️ Interactive Streamlit Interface: Dual-column layout with research summary and knowledge graph
- 📥 Query Input: Enter any research topic to initiate a new research flow
- 🤖 LangGraph Execution: Dynamically traverses reasoning steps as a graph pipeline
- 🔄 Step Tracker: Real-time progress indicator for each step in the graph
- 🧾 Summary Output: Final report includes refined insights with extracted <think> blocks
- 🕸️ Knowledge Graph Visualization:
      Expand/remove nodes on interaction
      Dynamically styled by label
      Supports multiple layouts (Dagre, Force, etc.)

---

## 📁 Project Structure

```
REMOTE-WORK-RESEARCH-AGENT/
├── data/
│   └── data.json                 # Final graph output
├── src/
│   ├── agents/
│   │   ├── document_processor.py
│   │   ├── information_gatherer.py
│   │   ├── json_generator.py     
│   │   ├── report_generator.py
│   │   ├── research_planner.py
│   │   └── synthesizer.py
│   ├── graph/
│   │   ├── edges.py
│   │   ├── nodes.py
│   │   ├── runner.py
│   │   └── state.py
│   ├── memory/
│   ├── ui/
│   └── utils/
│       ├── citation.py
│       ├── documents.py
│       └── search_api.py
├── tests/
├── streamlit_app.py              # Main UI app
├── requirements.txt
├── LICENSE
└── README.md
```

---

## ⚙️ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/research-agent.git
cd research-agent
```

### 2. Create and Activate Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate  # macOS/Linux
.venv\Scripts\activate     # Windows
```

### 3. Install Requirements

```bash
pip install -r requirements.txt
```

### 4. Set Environment Variables

Create a `.env` file in the root directory:

```
GROQ_API_KEY=your_groq_api_key
SERPAPI_API_KEY=your_serpapi_key
```

---

## 🧪 Run the Streamlit App

```bash
streamlit run src/ui/streamlit_app.py
```

---

## 📝 Example Usage

1. Enter a topic like:  
   `Recent advancements in battery technology`

2. App will:
   - 🔍 Search the web and arXiv for relevant content
   - 📄 Extract and preprocess PDFs or text
   - 🧠 Use LLaMA 3 (via Groq API) to synthesize insights
   - 📝 Generate a structured markdown report with headings and citations
   - 🕸️ Create an interactive knowledge graph from the report

---

## 🧾 Output Format

```markdown
# Research Summary Report

## Battery Innovation
...

📚 Citations:
- Title (Year) - Author 1, Author 2. [PDF](url)

*Generated by Research Agent*
```

---

## ✅ Notes

- LLaMA 3 is used via Groq's hosted inference endpoint
- Up to 5 documents are passed to the model to avoid context overflow
- No memory or follow-up support in this version (stateless)

---

