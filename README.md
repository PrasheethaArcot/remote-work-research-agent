<img width="1281" height="854" alt="Screenshot 2025-07-20 at 11 39 55 AM" src="https://github.com/user-attachments/assets/6173a6cc-1cb7-4a30-9b54-01915473fb59" />


<img width="1160" height="684" alt="Screenshot 2025-07-20 at 12 48 45 PM" src="https://github.com/user-attachments/assets/4950aa83-038d-4975-bca8-7ba006914471" />



# 🧠 Research Agent

Research Agent is a modular, automated research assistant built with LangGraph, LangChain, and LLMs. Given a single research query, it executes a complete multi-step pipeline:

- Plans the Research Scope: Breaks down the main query into relevant subtopics using an LLM-powered planner.

- Gathers Documents: Searches academic and web sources (e.g., arXiv, news, blogs) to retrieve high-quality, relevant documents.

- Processes and Filters Content: Parses retrieved content, extracts key text from summaries or full PDFs, and filters noise.

- Synthesizes a Report: Generates a structured, human-readable research report across all subtopics using LLM synthesis.

- Handles Citations Automatically: Formats both raw citation metadata and readable references for inclusion in the report or UI.

- Modular & Extensible: Each step (planning, search, processing, synthesis, citation) is a standalone LangGraph node — easily extendable or swappable.

---

## 🚀 Features

- 🌐 Web & academic search (Google & arXiv)
- 📄 PDF and text document extraction
- 🧠 LLM-based synthesis using LLaMA 3 via Groq API
- 📝 Structured report generation with markdown formatting
- 🔗 Citation generation in APA style
- 🖥️ Interactive Streamlit interface

---

## 📁 Project Structure

```
src/
├── agents/
│   ├── document_processor.py       # Extracts text + builds citation dicts
│   ├── information_gatherer.py     # Merges results from web and academic APIs
│   ├── report_generator.py         # Final markdown formatting
│   ├── research_generator.py       # Initializes subtopics for research
│   └── synthesizer.py              # Sends prompt to LLM and adds citations
├── graph/
│   ├── edges.py                    # Flow logic between agent steps
│   ├── nodes.py                    # Node wrappers for each agent
│   ├── runner.py                   # Runs the full research pipeline
│   └── state.py                    # Maintains shared state across steps
├── ui/
│   └── streamlit_app.py            # Frontend interface
└── utils/
    ├── citation.py                # APA citation formatting
    ├── documents.py               # PDF/text extraction logic
    └── search_api.py              # Google (SerpAPI) and arXiv search
```

---

## ⚙️ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/research-agent.git
cd research-agent
```

### 2. Create and Activate Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate  # macOS/Linux
.venv\Scripts\activate     # Windows
```

### 3. Install Requirements

```bash
pip install -r requirements.txt
```

### 4. Set Environment Variables

Create a `.env` file in the root directory:

```
GROQ_API_KEY=your_groq_api_key
SERPAPI_API_KEY=your_serpapi_key
```

---

## 🧪 Run the Streamlit App

```bash
streamlit run src/ui/streamlit_app.py
```

---

## 📝 Example Usage

1. Enter a topic like:  
   `Recent advancements in battery technology`

2. App will:
   - Search web and arXiv
   - Extract content
   - Generate a summary
   - Output a structured markdown report with citations

---

## 🧾 Output Format

```markdown
# Research Summary Report

## Battery Innovation
...

📚 Citations:
- Title (Year) - Author 1, Author 2. [PDF](url)

*Generated by Research Agent*
```

---

## ✅ Notes

- LLaMA 3 is used via Groq's hosted inference endpoint
- Up to 5 documents are passed to the model to avoid context overflow
- No memory or follow-up support in this version (stateless)

---

