<img width="1281" height="854" alt="Screenshot 2025-07-20 at 11 39 55â€¯AM" src="https://github.com/user-attachments/assets/6173a6cc-1cb7-4a30-9b54-01915473fb59" />


<img width="1160" height="684" alt="Screenshot 2025-07-20 at 12 48 45â€¯PM" src="https://github.com/user-attachments/assets/4950aa83-038d-4975-bca8-7ba006914471" />



# ğŸ§  Research Agent

Research Agent is a modular, automated research assistant built with LangGraph, LangChain, and LLMs. Given a single research query, it executes a complete multi-step pipeline:

- Plans the Research Scope: Breaks down the main query into relevant subtopics using an LLM-powered planner.

- Gathers Documents: Searches academic and web sources (e.g., arXiv, news, blogs) to retrieve high-quality, relevant documents.

- Processes and Filters Content: Parses retrieved content, extracts key text from summaries or full PDFs, and filters noise.

- Synthesizes a Report: Generates a structured, human-readable research report across all subtopics using LLM synthesis.

- Handles Citations Automatically: Formats both raw citation metadata and readable references for inclusion in the report or UI.

- Modular & Extensible: Each step (planning, search, processing, synthesis, citation) is a standalone LangGraph node â€” easily extendable or swappable.

---

## ğŸš€ Features

- ğŸŒ Web & academic search (Google & arXiv)
- ğŸ“„ PDF and text document extraction
- ğŸ§  LLM-based synthesis using LLaMA 3 via Groq API
- ğŸ“ Structured report generation with markdown formatting
- ğŸ”— Citation generation in APA style
- ğŸ–¥ï¸ Interactive Streamlit interface

---

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ document_processor.py       # Extracts text + builds citation dicts
â”‚   â”œâ”€â”€ information_gatherer.py     # Merges results from web and academic APIs
â”‚   â”œâ”€â”€ report_generator.py         # Final markdown formatting
â”‚   â”œâ”€â”€ research_generator.py       # Initializes subtopics for research
â”‚   â””â”€â”€ synthesizer.py              # Sends prompt to LLM and adds citations
â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ edges.py                    # Flow logic between agent steps
â”‚   â”œâ”€â”€ nodes.py                    # Node wrappers for each agent
â”‚   â”œâ”€â”€ runner.py                   # Runs the full research pipeline
â”‚   â””â”€â”€ state.py                    # Maintains shared state across steps
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ streamlit_app.py            # Frontend interface
â””â”€â”€ utils/
    â”œâ”€â”€ citation.py                # APA citation formatting
    â”œâ”€â”€ documents.py               # PDF/text extraction logic
    â””â”€â”€ search_api.py              # Google (SerpAPI) and arXiv search
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/research-agent.git
cd research-agent
```

### 2. Create and Activate Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate  # macOS/Linux
.venv\Scripts\activate     # Windows
```

### 3. Install Requirements

```bash
pip install -r requirements.txt
```

### 4. Set Environment Variables

Create a `.env` file in the root directory:

```
GROQ_API_KEY=your_groq_api_key
SERPAPI_API_KEY=your_serpapi_key
```

---

## ğŸ§ª Run the Streamlit App

```bash
streamlit run src/ui/streamlit_app.py
```

---

## ğŸ“ Example Usage

1. Enter a topic like:  
   `Recent advancements in battery technology`

2. App will:
   - Search web and arXiv
   - Extract content
   - Generate a summary
   - Output a structured markdown report with citations

---

## ğŸ§¾ Output Format

```markdown
# Research Summary Report

## Battery Innovation
...

ğŸ“š Citations:
- Title (Year) - Author 1, Author 2. [PDF](url)

*Generated by Research Agent*
```

---

## âœ… Notes

- LLaMA 3 is used via Groq's hosted inference endpoint
- Up to 5 documents are passed to the model to avoid context overflow
- No memory or follow-up support in this version (stateless)

---

